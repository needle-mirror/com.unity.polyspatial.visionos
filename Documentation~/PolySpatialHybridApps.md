---
uid: psl-vos-hybrid-apps
---
# PolySpatial Hybrid apps on visionOS
<a name="hybrid-mode"></a>
Hybrid apps combine the capabilities of [RealityKit](RealityKitApps.md) and [Metal](MetalApps.md) apps. Hybrid apps can make use of the Metal [volume camera mode](xref:Unity.PolySpatial.VolumeCamera.PolySpatialVolumeCameraMode), which can be used alongside **Bounded** and **Unbounded** mode to control whether or not rendering with Metal is active. When an active VolumeCamera is using a Metal output configuration, Unity will render the scene exactly the same way it would if the **App Mode** were set to Metal. Otherwise, RealityKit is used to render Unity content along with pass-through video, just as it would if the **App Mode** were set to RealityKit.

As with a VolumeCamera in Unbounded mode, a VolumeCamera in Metal mode does not have an output size. Content is not clipped or limited in any way based on where it is located in relation to the VolumeCamera. In fact, the transform of a Metal volume camera has no effect on the content in any way. The **CullingMask** field of the VolumeCamera is also ignored, along with the **Dimensions** field. Instead of using the VolumeCamera transform and properties, _regular Unity Cameras_ are used for rendering. The camera's CullingMask, Transform, etc. all affect what users will see, just as they do in visionOS apps configured for Metal mode and apps built for other XR platforms. As with other XR platforms, Hybrid visionOS apps use **XROrigin** to how the real-world tracking space is aligned with the Unity scene when a Metal VolumeCamera is in use. Refer to [Metal-based Apps on visionOS](MetalApps.md) for more information.

Of course, what sets the Hybrid **App Mode** apart from Metal is that RealityKit with PolySpatial is also available. You can use **Bounded** and **Unbounded** output configurations in addition to **Metal**, allowing your app to switch back and forth between using RealityKit and Metal for rendering content in the Immersive Space. While pass-through video was not available when using Metal rendering on visionOS 1, visionOS 2 introduced the ability to use Metal rendering with the `Mixed` immersion style. When using Mixed immersion, set your Unity camera's `ClearFlags` to `Solid Color` and ensure that the alpha value of this color is 0 in order to display pass-through video. You can switch `ClearFlags` back to `Skybox` at any time to render the skybox instead of pass-through. When your app activates Metal, the system presents a CompositorLayer which Unity uses as a render surface. When the Metal VolumeCamera is deactivated or its mode is changed to **Bounded** or **Unbounded**, the CompositorLayer is dismissed, and pass-through becomes visible again. The same constraints and requirements apply to RealityKit content in the Hybrid **App Mode** as they do in the RealityKit **App Mode**. For example, custom shaders must be implemented using ShaderGraph, and ARKit features require the use of an **Unbounded** VolumeCamera. Refer to [RealityKit Apps on visionOS](RealityKitApps.md) for more information.

# Hybrid Mode Constraints
Hybrid mode provides a unique opportunity to leverage the full capabilities of Unity on visionOS. Users don't need to compromise on Unity-specific rendering features that are not possible with RealityKit, and can still take advantage of RealityKit features like volumes. Unfortunately, this flexibility still comes with some constraints. Some of these constraints are defined imposed the platform, and some are a result of how Unity works under the hood. We're always working on making Unity better, and we'll point out which of these constraints may be improved in future releases of Unity and PolySpatial. As a general rule, any capabilities or limitations that apply to the Metal or RealityKit **App Modes** apply to Hybrid apps when one or the other mode is active. For example, ARKit data is still not available unless your app is _currently_ using an ImmersiveSpace, which means either Metal is active or an Unbounded VolumeCamera is in use.

The chief drawback of Hybrid mode in its current form is performance overhead. In the Metal and RealityKit app modes, we are able to conserve resources by either running Unity in batch mode (a.k.a "headless" mode, which doesn't open windows or render to the screen) for RealityKit mode, or disabling PolySpatial for Metal mode. Hybrid mode apps require Unity's full rendering pipeline, which rules out batch mode, and need PolySpatial to be running in order to use RealityKit. Even if your scene only has one VolumeCamera set to Metal mode, PolySpatial will still be tracking object changes and sending commands to the RealityKit backend. These commands result in a scene full of Entities that are not visible, which means that RealityKit isn't actually doing the bulk of the work it would otherwise be doing, but still this is a small performance cost that will scale with the complexity of your scene. Likewise, when Metal is not active, and your app is only using RealityKit for rendering, Unity is doing a little bit of extra work sending commands to the GPU as if it were going to render to the screen. This can be minimized by disabling any Cameras in your scene and even if there is a camera rendering, we avoid the bulk of the work because the GPU will refuse to execute those commands. In both cases, we are working on future improvements to reduce the overhead of PolySpatial when Unity is the only active renderer, and to reduce the overhead of Unity's graphics pipeline when RealityKit is the only active renderer.

Metal rendering _cannot be combined_ with the **Stereo Render Target** feature because they both require the use of an **XR Display Subsystem**. It may be possible to combine the use of these features in future package releases.

A VolumeCamera configured for Metal cannot be active at the same time as one configured for Unbounded RealityKit. This is a limitation imposed by the platform. Unbounded RealityKit content and Metal content both require an **ImmersiveSpace** on visionOS. Only one **ImmersiveSpace** can be used at a time, and RealityKit content cannot share an ImmersiveSpace with a **CompositorLayer**.

It is possible to display any combination of windows and volumes on top of a Metal space. Volumes and windows will always be drawn on top of Metal content, regardless of depth.

The transition in and out of Metal rendering is _not instant_, and can't always be done in a seamless manner. What this means, in practice, is that users will always see at least a second or two of pass-through in between Unbounded RealityKit and Metal mode. The easiest way to learn what the transitions look like is to just build the samples and try switching modes. Short of that, it will help to walk through a concrete example. Here is what a user will see when using a Hybrid app built with Unity, which uses a volume as its **start-up scene**:

1. The user taps the app icon on the Home Screen to launch the app. The home screen disappears.
2. A square window appears while the app is loading, showing the app's icon in the center.
3. A volume appears with some 3D content, including an affordance to switch to Metal mode. The user activates this affordance.
4. The volume disappears and the user is prompted with a dialog asking them to be mindful of their surroundings, which they can dismiss by clicking "OK" or "Don't Show Again." After responding to the dialog, the user will see pass-through for a moment before the Metal scene fades into view. Clicking "Don't Show Again" will skip the dialog next time, but not the moment of pass-through before the Metal layer is visible. If any other apps were running, their windows and volumes disappear at the same time as the app's volume. It is possible for your app's volume to persist across the transition, although even if it does, it will disappear temporarily if/when the safety dialog is presented.
5. At this point, the app can show additional windows or volumes on top of the Metal layer, but it is not possible to render RealityKit objects in an immersive space (outside of a volume). Shared mode apps will not be visible. **ARKit** data is available, and the system may prompt the user for additional authorizations as features that require them are enabled. These prompts and other OS dialogs will appear on top of the Metal layer.
6. The user gazes at an affordance in the Metal scene and pinches their fingers to initiate a transition back to RealityKit. In this case, the app will transition to an Unbounded RealityKit scene. The Metal layer fades out and RealityKit content immediately fades into view. During the transition, pass-through video is visible, although depending on the scene content, virtual content may continue to remain visible as a semi-transparent overlay throughout the transition, with its opacity reduced briefly to 0% and rising back to 100% over the course of about one second.
7. In this Unbounded RealityKit scene, **ARKit** features are available, and the app can open additional windows or volumes. These windows or volumes would also have remained visible in the same location throughout both the transition into Metal and back into RealityKit as long as the safety dialog was previously dismissed with "Don't Show Again." The safety dialog will hide all windows and volumes while it is being presented. At this point, it would be possible to dismiss the RealityKit ImmersiveSpace by disabling its VolumeCamera or changing its output configuration, at which point apps in the shared space would become visible alongside any windows or volumes opened by the app.
8. Instead, the user activates an affordance to switch to Metal mode once again. In this case, a small window appears briefly which simply contains the text "Loading..." Unbounded RealityKit content fades away and the Metal layer fades into view. If the user didn't click "Don't Show Again" earlier, the safety dialog is presented after the Loading window appears. After the user dismisses the safety dialog, the loading window is visible again briefly on top of pass-through as the Metal layer fades into view. The loading window is required to "bridge the gap" between dismissing the RealityKit ImmersiveSpace and opening the Metal ImmersiveSpace. If no windows or volumes are visible during this transition, the app is backgrounded and the Home Screen appears. This window is not required when transitioning into a fully immersive space, but is always required when transitioning from an ImmersiveSpace with one of the other ImmersionStyles (Mixed or Progressive) into a fully immersive space or between fully immersive spaces when no windows or volumes are open.
9. The user activates an affordance to open a volume with RealityKit content, and finally activates another affordance to dismiss the Metal space. The Metal layer fades out of view, and other apps that were running in the shared space are visible again.

At this point, we've covered all of the different transitions that can occur. When transitioning from a mixed or progressive immersive space to a fully immersive space (or if no immersive space was previously open), the user will see a safety dialog, or in its absence a brief fade-out-and-then-in between virtual content and pass-through. If there was no RealityKit volume open prior to this transition, a Loading window is used to bridge the gap. When transitioning from Metal to Unbounded RealityKit, the user will also briefly see pass-through, even if the Unbounded RealityKit scene will completely block pass-through when it becomes visible.

Note: The scenario above assumes that you have not modified the Xcode project generated by Unity. Different settings for the RealityKit ImmersiveSpace **ImmersionStyle** or other modifications to the SwiftUI scene may result in different behavior. Unfortunately, there is no way to avoid fading in and out of pass-through and presenting the user with a safety dialog when using a fully immersive space.

# Input in Hybrid Mode
The gaze/pinch gesture is available at all times in Hybrid mode. The same limitations apply to data about input device pose and selection ray when only using a Bounded VolumeCamera. Both **SpatialPointerDevice** and **VisionOSSpatialPointerDevice** are used, as described in the [Input](Input.md) section of the documentation. **ARKit** data is available as long as a Metal is active, or an Unbounded VolumeCamera is in use.

# Default Volume Configuration
As is the case when using the RealityKit **App Mode**, the **Default Volume Configuration** in **Player Settings** is responsible for determining the _start-up scene_ for your app. This start-up scene can either be a Bounded volume, an Unbounded RealityKit volume, or an Metal space. It is recommended that you assign the same **Volume Camera Output Configuration** asset which will be used by the first active VolumeCamera in your app to the **Default Volume Configuration** setting in **Player Settings / PolySpatial**. When launching directly into Metal, users will be prompted with the safety dialog right away, whereas launching directly into either RealityKit mode will continue to see pass-through until the app transitions to Metal mode. Apps that use a Bounded volume as their start-up scene will display a square window with the app icon in the center, while apps that use an Unbounded volume will not display anything until Unity has finished loading their start-up scene and sent commands to RealityKit to place objects in the scene.

# Using the same scene for Metal and RealityKit

Depending on the content, it may make sense to create a separate version of your scene for RealityKit, and one for Metal rendering with Unity. However, this may not always be the case. Most of the default materials and shaders will work equally well in RealityKit as in Metal, and camera/lighting settings configured for Metal generally won't have an impact on rendering the scene in RealityKit. Things can get a little more complicated when using baked lighting or complex rendering features in Metal, but it's a good idea to at least see what your scene looks like simply switching your volume camera output configuration between Metal and Unbounded. For simple material tweaks, [material swap sets](xref:Unity.PolySpatial.MaterialSwapSet) can be used to substitute materials in the scene used by Metal mode for an alternate material which will be used in RealityKit mode.

You will also want to configure your input scripts to use both **SpatialPointerDevice** and **VisionOSSpatialPointerDevice**, as described in the [Input](Input.md) section of the documentation.
